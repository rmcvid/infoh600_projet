{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 1 — Chargement du modèle LDA et des données d’entraînement**\n",
        "\n",
        "- Importe les librairies nécessaires (zipfile, os, joblib, pandas, numpy, etc.).\n",
        "- Dézippe le fichier `Q5_model_LDA_V3.zip` dans `/content`.\n",
        "- Définit le dossier du modèle : `MODEL_DIR = \"/content/Q5_model_LDA_V3\"`.\n",
        "- Charge :\n",
        "  - le modèle LDA entraîné (`lda_model.joblib`),\n",
        "  - le vectorizer `CountVectorizer` (`vectorizer.joblib`),\n",
        "  - la matrice des topics par playlist (`playlist_topic_matrix.joblib`),\n",
        "  - le DataFrame des playlists d’entraînement (`df_playlists.parquet`),\n",
        "  - le DataFrame des relations playlist–morceau (`df_pl_tracks.parquet`).\n",
        "- Affiche les shapes de `df_playlists` et `df_pl_tracks` pour vérifier que tout est bien chargé.\n"
      ],
      "metadata": {
        "id": "L78UAMyBhWQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# =========================\n",
        "# 1) Charger le modèle LDA + data TRAIN\n",
        "# =========================\n",
        "\n",
        "zip_path = \"/content/Q5_model_LDA_V3.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(\"/content\")\n",
        "\n",
        "MODEL_DIR = \"/content/Q5_model_LDA_V3\"\n",
        "\n",
        "\n",
        "lda = joblib.load(os.path.join(MODEL_DIR, \"lda_model.joblib\"))\n",
        "vectorizer = joblib.load(os.path.join(MODEL_DIR, \"vectorizer.joblib\"))\n",
        "playlist_topic_matrix = joblib.load(os.path.join(MODEL_DIR, \"playlist_topic_matrix.joblib\"))\n",
        "\n",
        "df_playlists = pd.read_parquet(os.path.join(MODEL_DIR, \"df_playlists.parquet\"))   # TRAIN playlists\n",
        "df_pl_tracks = pd.read_parquet(os.path.join(MODEL_DIR, \"df_pl_tracks.parquet\"))   # mapping pid -> tracks\n",
        "\n",
        "print(\"TRAIN shapes :\", df_playlists.shape, df_pl_tracks.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IVGmY4GQiDt",
        "outputId": "4f2188e8-6dc2-4341-8be6-ca6679b48771"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN shapes : (50000, 3) (3353026, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 2 — Charger le jeu de TEST (slice mise de côté)**\n",
        "\n",
        "- Charge le fichier `test_slices.parquet` qui contient les playlists réservées pour l’évaluation.\n",
        "- Ce dataset n’a **jamais** été utilisé pour entraîner le modèle, donc il sert à mesurer la performance réelle.\n",
        "- Affiche sa shape pour vérifier que les playlists test sont bien chargées.\n"
      ],
      "metadata": {
        "id": "WhzT2dtlhbGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2) Charger le jeu de TEST (slice mise de côté)\n",
        "# =========================\n",
        "\n",
        "df_playlists_test = pd.read_parquet(\"/content/Q5_model_LDA_V3/test_slices.parquet\")\n",
        "print(\"Shape df_playlists_test :\", df_playlists_test.shape)"
      ],
      "metadata": {
        "id": "zVVnYkQJQkfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c95132-e578-4d64-bffb-2732e1b40cef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape df_playlists_test : (1000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 3 — Construire les mappings tracks (TRAIN / TEST)**\n",
        "\n",
        "- Regroupe `df_pl_tracks` par `pid` pour obtenir, pour chaque playlist, l’ensemble des `track_uri`.\n",
        "- Sépare ces mappings en deux parties :\n",
        "  - `pl2tracks_train` : playlists utilisées pour l’entraînement.\n",
        "  - `pl2tracks_test` : playlists utilisées uniquement pour l’évaluation.\n",
        "- Crée également `track_meta`, un petit tableau utile pour afficher le nom et l’artiste d’un morceau à partir de son `track_uri`.\n"
      ],
      "metadata": {
        "id": "a4-jrcb1hjPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3) Construire les mappings tracks (TRAIN / TEST)\n",
        "# =========================\n",
        "\n",
        "# mapping global pid -> set(track_uri)\n",
        "pl2tracks_all = df_pl_tracks.groupby(\"pid\")[\"track_uri\"].apply(lambda s: set(s)).to_dict()\n",
        "\n",
        "train_pids = set(df_playlists[\"pid\"])\n",
        "test_pids  = set(df_playlists_test[\"pid\"])\n",
        "\n",
        "# mapping TRAIN : pid (train) -> tracks\n",
        "pl2tracks_train = {pid: tracks for pid, tracks in pl2tracks_all.items() if pid in train_pids}\n",
        "# mapping TEST : pid (test) -> tracks\n",
        "pl2tracks_test  = {pid: tracks for pid, tracks in pl2tracks_all.items() if pid in test_pids}\n",
        "\n",
        "# meta par track_uri (pour lisibilité éventuelle)\n",
        "track_meta = (\n",
        "    df_pl_tracks\n",
        "      .sort_values(\"track_name\")\n",
        "      .drop_duplicates(\"track_uri\")[[\"track_uri\", \"track_name\", \"artist_name\"]]\n",
        ")"
      ],
      "metadata": {
        "id": "q3QgQ-MtQl6B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 4 — Normalisation des vecteurs de topics (TRAIN)**\n",
        "\n",
        "- Normalise chaque vecteur de topics de `playlist_topic_matrix` pour qu’il ait une norme 1.\n",
        "- Cette normalisation permet de calculer la similarité cosinus entre playlists.\n",
        "- `playlist_norm` est donc la version normalisée, utilisée plus tard pour trouver les playlists voisines.\n"
      ],
      "metadata": {
        "id": "nru09qQ_hnIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4) Normalisation des topics TRAIN pour cosinus\n",
        "# =========================\n",
        "\n",
        "playlist_norm = playlist_topic_matrix / (\n",
        "    np.linalg.norm(playlist_topic_matrix, axis=1, keepdims=True) + 1e-12\n",
        ")\n"
      ],
      "metadata": {
        "id": "0oXDBaTbQotb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 5 — Calcul des topics pour les playlists de TEST**\n",
        "\n",
        "- Nettoie le texte des playlists de test en appliquant la même fonction `clean_text` que pour le TRAIN.\n",
        "- Transforme ces textes en vecteurs Bag-of-Words **avec le vectorizer entraîné sur le TRAIN**  \n",
        "  (important : on n'appelle **pas** `fit`, seulement `transform`).\n",
        "- Projette ces vecteurs BoW dans l’espace des topics grâce au modèle LDA entraîné.\n",
        "- Le résultat `playlist_topic_test` contient un vecteur de topics pour chaque playlist de TEST.\n"
      ],
      "metadata": {
        "id": "OykseD9ghpmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5) Topics pour les playlists de TEST\n",
        "# =========================\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9]+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "df_playlists_test[\"clean_text\"] = df_playlists_test[\"text\"].astype(str).apply(clean_text)\n",
        "\n",
        "# BoW sur le TEST (vectorizer entraîné sur le TRAIN)\n",
        "X_bow_test = vectorizer.transform(df_playlists_test[\"clean_text\"])\n",
        "\n",
        "# Projeter dans l'espace LDA (inférence)\n",
        "playlist_topic_test = lda.transform(X_bow_test)\n",
        "print(\"Shape playlist_topic_test :\", playlist_topic_test.shape)"
      ],
      "metadata": {
        "id": "SL6HcJzCQqRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fdcc89-295b-489b-b68e-c7453f4c235d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape playlist_topic_test : (1000, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 6 — Recherche des voisins et génération des recommandations (TEST)**\n",
        "\n",
        "- `top_k_neighbors_for_query_theta` :\n",
        "  - prend le vecteur de topics d’une playlist TEST (`theta_query`),\n",
        "  - calcule sa similarité cosinus avec **toutes les playlists TRAIN**,\n",
        "  - retourne les `k` playlists les plus similaires.\n",
        "\n",
        "- `recommend_tracks_for_test_pid_with_seeds` :\n",
        "  - récupère le vecteur LDA de la playlist TEST (déjà calculé à l'étape précédente),\n",
        "  - trouve ses `k` playlists voisines dans le TRAIN,\n",
        "  - agrège les morceaux présents dans ces playlists voisines,\n",
        "  - exclut les morceaux déjà présents dans les seed tracks,\n",
        "  - renvoie les 500 recommandations les mieux scorées.\n",
        "\n",
        "\n",
        "Ces fonctions permettent d’effectuer des recommandations pour **une playlist de TEST**, en s’appuyant uniquement sur les playlists d’entraînement.\n"
      ],
      "metadata": {
        "id": "Wum--JluhzDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 6) Voisins & reco pour une playlist TEST (via θ_test)\n",
        "# =========================\n",
        "\n",
        "def top_k_neighbors_for_query_theta(theta_query, k=500):\n",
        "    \"\"\"\n",
        "    theta_query : vecteur topics (1D) d'une playlist TEST\n",
        "    Retourne des voisins parmi les playlists TRAIN (df_playlists, playlist_norm)\n",
        "    \"\"\"\n",
        "    q = theta_query.reshape(1, -1)\n",
        "    q_norm = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)\n",
        "    sims = (q_norm @ playlist_norm.T).ravel()  # similarité avec TOUTES les playlists TRAIN\n",
        "\n",
        "    nn = np.argpartition(-sims, k)[:k]\n",
        "    nn = nn[np.argsort(-sims[nn])]\n",
        "    return nn, sims[nn]\n",
        "\n",
        "def recommend_tracks_for_test_pid_with_seeds(query_pid, seed_tracks, topn=500, k_neighbors=500):\n",
        "    \"\"\"\n",
        "    Recommandations pour une playlist de TEST :\n",
        "    - on utilise les topics calculés pour le TEST comme requête\n",
        "    - on va chercher des voisins dans le TRAIN\n",
        "    - on agrège les tracks des voisins TRAIN (en excluant les seed_tracks)\n",
        "    \"\"\"\n",
        "    # index de la playlist dans df_playlists_test\n",
        "    rows = df_playlists_test.index[df_playlists_test[\"pid\"] == query_pid]\n",
        "    if len(rows) == 0:\n",
        "        raise ValueError(f\"PID {query_pid} pas trouvé dans df_playlists_test\")\n",
        "    pl_idx_test = int(rows[0])\n",
        "\n",
        "    theta_q = playlist_topic_test[pl_idx_test]\n",
        "\n",
        "    # voisins côté TRAIN\n",
        "    nn_idx, nn_sims = top_k_neighbors_for_query_theta(theta_q, k=k_neighbors)\n",
        "    nn_pids = df_playlists.iloc[nn_idx][\"pid\"].to_numpy()  # voisins = TRAIN\n",
        "\n",
        "    query_tracks = set(seed_tracks)\n",
        "\n",
        "    scores = defaultdict(float)\n",
        "    for pid, s in zip(nn_pids, nn_sims):\n",
        "        for t in pl2tracks_train.get(pid, ()):  # tracks des PLAYLISTS TRAIN\n",
        "            if t not in query_tracks:\n",
        "                scores[t] += float(s)\n",
        "\n",
        "    items = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:topn]\n",
        "    recs = pd.DataFrame(items, columns=[\"track_uri\", \"score\"])\n",
        "    recs = recs.merge(track_meta, on=\"track_uri\", how=\"left\")\n",
        "    return recs[[\"track_uri\", \"track_name\", \"artist_name\", \"score\"]]"
      ],
      "metadata": {
        "id": "BqVm_jkcQtBZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 7 — Construction des seeds et définition de la métrique Recall@500 (TEST uniquement)**\n",
        "\n",
        "- Définit `K = 25`, le nombre de morceaux conservés comme **seed tracks** (les seuls connus de la playlist côté utilisateur).\n",
        "- Sélectionne les playlists de TEST ayant au moins `K + 1` morceaux, pour pouvoir séparer seed et ground truth.\n",
        "- Tire aléatoirement un échantillon de playlists de TEST (jusqu’à 1000) pour l’évaluation.\n",
        "- Fonction `make_seed_and_ground_truth_test` :\n",
        "  - tire `K` morceaux comme **seeds**,\n",
        "  - utilise le reste comme **ground truth** (GT), c’est-à-dire les morceaux que le modèle doit retrouver.\n",
        "- Fonction `recall_at_500` :\n",
        "  - calcule le **Recall@500**, soit la proportion de GT retrouvée dans les 500 recommandations retournées par le modèle.\n"
      ],
      "metadata": {
        "id": "t9cEdhJsh9AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 7) Construction des seeds & métrique Recall@500 (TEST uniquement)\n",
        "# =========================\n",
        "\n",
        "K = 25  # nombre de seed tracks\n",
        "\n",
        "# playlists de TEST avec au moins K+1 morceaux\n",
        "eval_pids_test = [\n",
        "    pid for pid, tracks in pl2tracks_test.items()\n",
        "    if len(tracks) > K + 1\n",
        "]\n",
        "\n",
        "print(\"Nombre de playlists TEST éligibles :\", len(eval_pids_test))\n",
        "\n",
        "random.seed(42)\n",
        "eval_pids_sample_test = random.sample(eval_pids_test, k=min(1000, len(eval_pids_test)))\n",
        "print(\"Nombre de playlists TEST utilisées pour l'évaluation :\", len(eval_pids_sample_test))\n",
        "\n",
        "def make_seed_and_ground_truth_test(pid, K):\n",
        "    tracks = list(pl2tracks_test[pid])\n",
        "    if len(tracks) <= K:\n",
        "        return None, None\n",
        "    seed_tracks = set(random.sample(tracks, K))\n",
        "    gt_tracks = set(tracks) - seed_tracks\n",
        "    return seed_tracks, gt_tracks\n",
        "\n",
        "def recall_at_500(gt_tracks, rec_uris):\n",
        "    \"\"\"\n",
        "    Recall@500 = (# de tracks de la ground truth retrouvés dans le top 500)\n",
        "                 / (# de tracks dans la ground truth)\n",
        "    \"\"\"\n",
        "    gt = set(gt_tracks)\n",
        "    if not gt:\n",
        "        return 0.0\n",
        "    rec = set(rec_uris[:500])\n",
        "    return len(gt & rec) / len(gt)"
      ],
      "metadata": {
        "id": "WXKYNB0kQvcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a90859-050a-4e03-fa72-c1de0a4e1d7b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de playlists TEST éligibles : 733\n",
            "Nombre de playlists TEST utilisées pour l'évaluation : 733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 8 — Boucle d’évaluation sur le TEST (≈ 3 minutes)**\n",
        "\n",
        "- Parcourt chaque playlist sélectionnée pour l’évaluation.\n",
        "- Pour chaque playlist de TEST :\n",
        "  1. Génère ses **seed tracks** et sa **ground truth**.\n",
        "  2. Appelle la fonction de recommandation basée sur les **topics TEST** et les **voisins TRAIN**.\n",
        "  3. Récupère les 500 recommandations produites.\n",
        "  4. Calcule le **Recall@500** en comparant ces recommandations à la ground truth.\n",
        "- Stocke la valeur du Recall pour chaque playlist.\n",
        "- Affiche :\n",
        "  - le nombre total de playlists évaluées,\n",
        "  - la moyenne du Recall@500,\n",
        "  - la médiane du Recall@500.\n",
        "\n",
        "\n",
        "Ce STEP fournit un indicateur global de performance du modèle LDA + k-NN sur le **jeu de TEST**, totalement séparé du train.\n"
      ],
      "metadata": {
        "id": "p3UVXAJWiIfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y5jr2z4gQamx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d155c7-cab3-43a5-ec0e-e474464868c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de playlists TEST évaluées : 733\n",
            "Recall@500 TEST moyen : 0.1225136185388589\n",
            "Recall@500 TEST médian : 0.08\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# 8) Boucle d'évaluation sur le TEST (3' pour run)\n",
        "# =========================\n",
        "\n",
        "recalls_test = []\n",
        "\n",
        "for pid in eval_pids_sample_test:\n",
        "    seed_tracks, gt_tracks = make_seed_and_ground_truth_test(pid, K)\n",
        "    if not seed_tracks or not gt_tracks:\n",
        "        continue\n",
        "\n",
        "    recs = recommend_tracks_for_test_pid_with_seeds(\n",
        "        pid,\n",
        "        seed_tracks,\n",
        "        topn=500,\n",
        "        k_neighbors=500\n",
        "    )\n",
        "    rec_uris = recs[\"track_uri\"].tolist()\n",
        "\n",
        "    r = recall_at_500(gt_tracks, rec_uris)\n",
        "    recalls_test.append(r)\n",
        "\n",
        "print(\"Nombre de playlists TEST évaluées :\", len(recalls_test))\n",
        "print(\"Recall@500 TEST moyen :\", float(np.mean(recalls_test)))\n",
        "print(\"Recall@500 TEST médian :\", float(np.median(recalls_test)))\n"
      ]
    }
  ]
}