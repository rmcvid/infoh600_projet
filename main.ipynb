{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb00c6c6",
   "metadata": {},
   "source": [
    "# Ouverture du fichier\n",
    "Vous pouvez cloner le fichier par contre il faudra que vous ajoutiez le fichier challenge_set.json qui est trop volumineux pour github. Celui-ci se trouve dans le dossier `spotify_million_playlist_dataset_challenge` qui lui même est donné en suivant les liens qui se trouvent dans les consignes. Une fois que vous avez mis ce fichier dans votre dossier avec le code. tout devrait run sans problème\n",
    "Faites un `Ctrl+F` avec \"ici\" pour trouver tous les endroits où il y a un petit bug ou une optimisation à faire.  \n",
    "\n",
    "---\n",
    "\n",
    "## Done\n",
    "\n",
    "Les df créés sont les suivants :\n",
    "\n",
    "- **`df_playlists`** : contient toutes les playlists avec leurs noms et leurs paramètres.  \n",
    "  La colonne `tracks` contient toutes les informations sur les musiques de la playlist, mais dans un format très « dirty ».\n",
    "\n",
    "- **`df_tracks`** : correspond à la colonne `playlists[\"tracks\"]`, un peu nettoyée.  \n",
    "  Une même musique peut apparaître plusieurs fois.\n",
    "\n",
    "- **`df_tracks_vectors`** : contient `track_id` et le vecteur `list_pid`de dimension 10 000 permettant de calculer la similarité entre deux musiques. Là par contre chaque musique aparait qu'une seule fois\n",
    "\n",
    "---\n",
    "\n",
    "## To do\n",
    "\n",
    "- Vérifier ou optimiser le code.  \n",
    "  Normalement, la question 3 est résolue.  \n",
    "  Il serait intéressant de créer une fonction qui accepte **l'artiste et le titre** pour être plus user-friendly, car la fonction actuelle n'accepte que des `track_id`.  \n",
    "  Il faudra préparer des exemples et tester avec potentiellement des musiques que l'on connait.\n",
    "- Un des \"ici\" correspond à un commentaire où j'essaie d'ajouter le nom de playlist dans une liste, mais cela ne fonctionne pas. Je ne comprends pas trop pourquoi, surtout que ça marche avec le `pid`. De facon dirty peut aller rechercher l'information après dans les autre df mais ce serait quand même moins optimal bien que fonctionel\n",
    "- Faire des statistiques descriptives pour la question 2.\n",
    "- Esquisser une formule pour la question 4\n",
    "- Esquisser une formule pour la question 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e65ac4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/opt/anaconda3/envs/environnement_test/lib/python313.zip\\\\challenge_set.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m here_Path = sys.path[\u001b[32m0\u001b[39m]\n\u001b[32m      2\u001b[39m data_Path = here_Path + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mchallenge_set.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_Path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m     data = json.load(f)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Extraire uniquement la liste des playlists\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/environnement_test/lib/python3.13/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/opt/anaconda3/envs/environnement_test/lib/python313.zip\\\\challenge_set.json'"
     ]
    }
   ],
   "source": [
    "here_Path = sys.path[0]\n",
    "data_Path = here_Path + \"\\\\challenge_set.json\"\n",
    "with open(data_Path, 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extraire uniquement la liste des playlists\n",
    "playlists = data[\"playlists\"]\n",
    "\n",
    "# Transformer en DataFrame\n",
    "df_playlists = pd.DataFrame(playlists)\n",
    "df_playlists[\"name\"] = df_playlists[\"name\"].astype(str)\n",
    "df_playlists[\"pid\"] = df_playlists[\"pid\"].astype(str)\n",
    "df_playlists.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da6ad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   name          10000 non-null  object\n",
      " 1   num_holdouts  10000 non-null  object\n",
      " 2   pid           10000 non-null  object\n",
      " 3   num_tracks    10000 non-null  object\n",
      " 4   tracks        10000 non-null  object\n",
      " 5   num_samples   10000 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = Path.cwd()  \n",
    "data_path = base_dir / \"spotify_million_playlist_dataset_challenge\" / \"challenge_set.json\"\n",
    "\n",
    "with data_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "playlists = data[\"playlists\"]\n",
    "\n",
    "df_playlists = pd.DataFrame(data[\"playlists\"], dtype=str)\n",
    "df_playlists[\"name\"] = df_playlists[\"name\"].astype(str)\n",
    "df_playlists[\"pid\"] = df_playlists[\"pid\"].astype(str)\n",
    "df_playlists.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ed28e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_playlists.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d6758",
   "metadata": {},
   "source": [
    "## On construit ici une df des tracks cleaned dans le sens ou les id sont débarrasé de *spotify:name:*\n",
    "    - pid = playlist id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d32a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ici le hardcode est pas propre mais bon\n",
    "all_tracks = []\n",
    "df_tracks = pd.DataFrame([])\n",
    "for pl in playlists:\n",
    "    for tr in pl[\"tracks\"]:\n",
    "        track_info = tr.copy()  # pour ne pas modifier l'objet original\n",
    "        #track_info[\"pname\"] = pl[\"name\"] ici je ne sais pas pourquoi mais il veut pas ajouter le nom de la playlist\n",
    "        track_info[\"pid\"] = pl[\"pid\"]\n",
    "        all_tracks.append(track_info)\n",
    "df_tracks = pd.DataFrame(all_tracks)\n",
    "# ici y'a moyen d'optimiser la boucle en la rentrant au dessus\n",
    "for i in ( \"track\", \"artist\", \"album\"):\n",
    "    df_tracks[i+\"_id\"] = df_tracks[i+\"_uri\"].str.split(\":\").str[-1]\n",
    "df_tracks.drop(columns=[\"track_uri\", \"artist_uri\", \"album_uri\"], inplace=True)\n",
    "#df_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cab6f",
   "metadata": {},
   "source": [
    "A priori, si $\\text{track\\_id}_i = \\text{track\\_id}_j$ :  \n",
    "\n",
    "$$\n",
    "\\text{artist\\_id}_i = \\text{artist\\_id}_j, \\quad\n",
    "\\text{album\\_id}_i = \\text{album\\_id}_j\n",
    "$$\n",
    "\n",
    "On peut donc chercher par `track_id` unique et créer une liste pour le `pid`. Ainsi, *list_pid* sera un vecteur de dimension $( \\text{ndim} = 10 000$. Seules les composantes non nulles sont conservées et valent 0 ou 1 si elles sont présentes dans la playlist.  \n",
    "Plutôt que de conserver les 0, on conserve uniquement les indices des playlists dans lesquelles la musique apparaît.  \n",
    "(On pourrait éventuellement retirer les playlists avec zéro track.)\n",
    "\n",
    "La similarité entre deux musiques peut alors se calculer de la façon suivante :  \n",
    "\n",
    "$$\n",
    "\\langle a, b \\rangle = \\frac{|a \\cap b|}{\\sqrt{\\text{len}(a) \\cdot \\text{len}(b)}} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f626cb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281000, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acd6ec8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_pid</th>\n",
       "      <th>pid_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7yyRTcZmCiyzzJlNzGC9Ol</th>\n",
       "      <td>[1000791, 1000859, 1001452, 1001497, 1001589, ...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5dNfHmqgr128gMY2tc5CeJ</th>\n",
       "      <td>[1001292, 1002975, 1003413, 1003871, 1004619, ...</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5XJJdNPkwmbUwE79gv0NxK</th>\n",
       "      <td>[1001692, 1007829, 1007941, 1008258, 1008788, ...</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62vpWI1CHwFy7tMIcSStl8</th>\n",
       "      <td>[1000789, 1000801, 1002510, 1003021, 1003028, ...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7BKLCZ1jbUBVqRi2FVlTVw</th>\n",
       "      <td>[1000430, 1000859, 1001897, 1002348, 1002729, ...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 list_pid  \\\n",
       "track_id                                                                    \n",
       "7yyRTcZmCiyzzJlNzGC9Ol  [1000791, 1000859, 1001452, 1001497, 1001589, ...   \n",
       "5dNfHmqgr128gMY2tc5CeJ  [1001292, 1002975, 1003413, 1003871, 1004619, ...   \n",
       "5XJJdNPkwmbUwE79gv0NxK  [1001692, 1007829, 1007941, 1008258, 1008788, ...   \n",
       "62vpWI1CHwFy7tMIcSStl8  [1000789, 1000801, 1002510, 1003021, 1003028, ...   \n",
       "7BKLCZ1jbUBVqRi2FVlTVw  [1000430, 1000859, 1001897, 1002348, 1002729, ...   \n",
       "\n",
       "                        pid_count  \n",
       "track_id                           \n",
       "7yyRTcZmCiyzzJlNzGC9Ol        226  \n",
       "5dNfHmqgr128gMY2tc5CeJ        222  \n",
       "5XJJdNPkwmbUwE79gv0NxK        215  \n",
       "62vpWI1CHwFy7tMIcSStl8        211  \n",
       "7BKLCZ1jbUBVqRi2FVlTVw        206  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks_vectors = (\n",
    "    df_tracks.groupby(\"track_id\", as_index=True).agg({\n",
    "        \"pid\": list\n",
    "    })\n",
    ")\n",
    "df_tracks_vectors.rename(columns={\"pid\": \"list_pid\"}, inplace=True)\n",
    "df_tracks_vectors[\"pid_count\"] = df_tracks_vectors[\"list_pid\"].apply(len)\n",
    "df_tracks_vectors = df_tracks_vectors.sort_values(\"pid_count\", ascending=False)\n",
    "df_tracks_vectors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb981f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66243, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0156dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_tracks(track_id1,track_id2):\n",
    "    try:\n",
    "        list1 = df_tracks_vectors.loc[track_id1, \"list_pid\"]\n",
    "        list2 = df_tracks_vectors.loc[track_id2, \"list_pid\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "    # transformer en sets pour calculer l'intersection\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    n_common = len(set1 & set2)\n",
    "    \n",
    "    if n_common == 0:\n",
    "        return 0.0\n",
    "    # ici à priori pas de division par zéro car len > 0 mais bon\n",
    "    return n_common / math.sqrt(len(set1) * len(set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d5117",
   "metadata": {},
   "source": [
    "# exemple d'utilisation de similar track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb7b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 musiques similaires : 1.000\n",
      "2 musiques du meme album  : 0.297\n",
      "2 musiques du meme album  : 0.096\n"
     ]
    }
   ],
   "source": [
    "print(f\"2 musiques similaires : {similar_tracks('66U0ASk1VHZsqIkpMjKX3B', '66U0ASk1VHZsqIkpMjKX3B'):.3f}\")\n",
    "print(f\"2 musiques du meme album  : {similar_tracks('35kahykNu00FPysz3C2euR', '3G6hD9B2ZHOsgf4WfNu7X1'):.3f}\")\n",
    "print(f\"2 musiques les plus partagées  : {similar_tracks('7yyRTcZmCiyzzJlNzGC9Ol', '5dNfHmqgr128gMY2tc5CeJ'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d606b96",
   "metadata": {},
   "source": [
    "# Q.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c5a07",
   "metadata": {},
   "source": [
    "L'idée est d'adopter la même logique que pour la question 3 sauf qu'ici l'idée n'est plus de représenter chaque track selon la liste de ses playlists mais plutôt de représenter chaque playlist par sa liste de tracks. L'espace de représentation est donc le nombre de tracks. \n",
    "\n",
    "Pour deux playlists P1 et P2 : \n",
    "+ T(P1) = l’ensemble des track_id dans la playlist 1\n",
    "+ T(P2) = l'ensemble des track_id de la playlist 2 \n",
    "\n",
    "On peut définir :\n",
    "\n",
    "$$\n",
    "\\langle P1, P2 \\rangle = \\frac{|T(P1) \\cap T(P2)|}{\\sqrt{\\text{len}(TP(1)) \\cdot \\text{len}(TP(2))}} \n",
    "$$\n",
    "\n",
    "Donc, deux playlists sont similaires si elles partagent beaucoup de morceaux, proportionnellement à leur longueur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73759571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1000002\n",
       "1       1000003\n",
       "2       1000004\n",
       "3       1000006\n",
       "4       1000007\n",
       "         ...   \n",
       "9995    1006767\n",
       "9996    1006771\n",
       "9997    1006773\n",
       "9998    1006775\n",
       "9999    1006778\n",
       "Name: pid, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_playlists['pid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on passe à une représentation une playlist -> liste de tracks. De la même manière qu'avant, chaque ligne représente une playliste et la liste de ses musiques \n",
    "\n",
    "df_playlist_vectors = (\n",
    "    df_tracks.groupby(\"pid\", as_index=True)\n",
    "             .agg({\"track_id\": list})\n",
    "             .rename(columns={\"track_id\": \"list_track_id\"})\n",
    ")\n",
    "df_playlist_vectors[\"track_count\"] = df_playlist_vectors[\"list_track_id\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d27a09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_track_id</th>\n",
       "      <th>track_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>[66U0ASk1VHZsqIkpMjKX3B, 5MhsZlmKJG6X5kTHkdwC4...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000001</th>\n",
       "      <td>[3kpM8OxeMaaAWI9pErdj1S, 4sj8qFcEDnRPNv3tBbUVU...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000009</th>\n",
       "      <td>[7rPLZ8Krm6CZIbraFUlnWZ, 4LloVtxNZpeh7q7xdi1DQ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000016</th>\n",
       "      <td>[6WQLkih8nE0JdUCEyLaGnQ, 37sINbJZcFdHFAsVNsPq1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000020</th>\n",
       "      <td>[4PvD06Pmbm2rHG2JjSlElF, 57nNNkgk768QVXq3uHxu5...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             list_track_id  track_count\n",
       "pid                                                                    \n",
       "1000000  [66U0ASk1VHZsqIkpMjKX3B, 5MhsZlmKJG6X5kTHkdwC4...            5\n",
       "1000001  [3kpM8OxeMaaAWI9pErdj1S, 4sj8qFcEDnRPNv3tBbUVU...           25\n",
       "1000009  [7rPLZ8Krm6CZIbraFUlnWZ, 4LloVtxNZpeh7q7xdi1DQ...           25\n",
       "1000016  [6WQLkih8nE0JdUCEyLaGnQ, 37sINbJZcFdHFAsVNsPq1...            5\n",
       "1000020  [4PvD06Pmbm2rHG2JjSlElF, 57nNNkgk768QVXq3uHxu5...            5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_playlist_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "627023be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_playlist_vectors.head()\n",
    "df_playlist_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149af9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "nb_playlists_total = df_playlists[\"pid\"].nunique()\n",
    "nb_playlists_non_vides = df_tracks[\"pid\"].nunique()\n",
    "nb_playlists_vides = nb_playlists_total - nb_playlists_non_vides\n",
    "print(nb_playlists_vides) #df_playlist_vectors ne contient que les playlists non-vides "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fc3d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on crée ensuite une fonction de similarité semblable à celle créée pour les tracks \n",
    "def similar_playlists(pid1, pid2):\n",
    "    try:\n",
    "        list1 = df_playlist_vectors.loc[pid1, \"list_track_id\"] # on récupère la liste des morceaux associés à la playlist pid1\n",
    "        list2 = df_playlist_vectors.loc[pid2, \"list_track_id\"] # on récupère la liste des morceaux associés à la playlist pid2\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "    set1, set2 = set(list1), set(list2) # on transforme en set pour n'avoir que des éléments uniques \n",
    "    n_common = len(set1 & set2)\n",
    "    if n_common == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return n_common / math.sqrt(len(set1) * len(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd2da50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(88, 1014985, 1028896), (59, 1028896, 1037525), (59, 1020013, 1024428), (58, 1023697, 1037525), (57, 1014985, 1037525)]\n"
     ]
    }
   ],
   "source": [
    "# helper fait avec chat pour avoir le top des playlists qui partagent le plus de sons pour faire quelques checks\n",
    "\n",
    "def top_common_playlists(limit=10):\n",
    "    # convertit une fois pour toutes en sets\n",
    "    playlist_sets = {\n",
    "        pid: set(row[\"list_track_id\"])\n",
    "        for pid, row in df_playlist_vectors.iterrows()\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for (pid1, set1), (pid2, set2) in combinations(playlist_sets.items(), 2):\n",
    "        common = len(set1 & set2)\n",
    "        if common > 0:\n",
    "            scores.append((common, pid1, pid2))\n",
    "    scores.sort(reverse=True)\n",
    "    return scores[:limit]\n",
    "\n",
    "pairs = top_common_playlists(5)\n",
    "print(pairs)  # listes de (nb commun, pid1, pid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd72db42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 playlists identiques : 1.000\n",
      "2 playlists avec un morceau commun : 0.142\n",
      "2 playlists les plus semblables (top 1) : 0.880\n",
      "2 playlists les plus semblables (top 2) : 0.580\n"
     ]
    }
   ],
   "source": [
    "print(f\"2 playlists identiques : {similar_playlists(1000000, 1000000):.3f}\") # doit renvoyer 1\n",
    "print(f\"2 playlists avec un morceau commun : {similar_playlists(1036931, 1037176):.3f}\") #contiennent toutes les deux Stays in Mexico \n",
    "print(f\"2 playlists les plus semblables (top 1) : {similar_playlists(1014985, 1028896):.3f}\") \n",
    "print(f\"2 playlists les plus semblables (top 2) : {similar_playlists(1023697, 1037525):.3f}\") #contiennent toutes les deux Stays in Mexico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d28f3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_track_id</th>\n",
       "      <th>track_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1023697</th>\n",
       "      <td>[3wkKkFAtYSTRwqOydW6T0I, 5rgy6ghBq1eRApCkeUdJX...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037525</th>\n",
       "      <td>[4P7VFiaZb3xrXoqGwZXC3J, 0DdpxWfVvUGgkJv5536ti...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             list_track_id  track_count\n",
       "pid                                                                    \n",
       "1023697  [3wkKkFAtYSTRwqOydW6T0I, 5rgy6ghBq1eRApCkeUdJX...          100\n",
       "1037525  [4P7VFiaZb3xrXoqGwZXC3J, 0DdpxWfVvUGgkJv5536ti...          100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_playlist_vectors.loc[[1023697,1037525]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd1089",
   "metadata": {},
   "source": [
    "Prochaines étapes : \n",
    "+ pondérer les tracks par leur popularité -> pour que les tracks populaires fassent moins exploser le score de similarité entre des playlists. Avec un truc comme # de playlists dans lesquelles apparaît le track / nombre total de playlists. L'intuition serait qu'un mocreau rare partagé entre deux playlists a plus de poids dans la définition de similarité qu'un morceau qui est très connu. \n",
    "+ introduire un score selon le nom des artistes partagés ou albums partagés même si ce ne sont pas les mêmes musiques ? Mais un artiste peut avoir plusieurs styles et idem pour un album\n",
    "+ similarité dans le nom des playlists -> similarité : sport, muscu, course à pied etc/ relaxation, détente, etc./ étude, focus, etc. J'ai vu certaines playlists appelées workout. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environnement_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
